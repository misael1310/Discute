import os
import io
import tempfile
from typing import Optional

import whisper
import torchaudio
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model

# Load environment variables from .env file
load_dotenv()


class MissingAPIKeyError(Exception):
    """Raised when the GROQ API key is missing or invalid."""

    def __init__(self, message: Optional[str] = None) -> None:
        if message is None:
            message = "GROQ_API_KEY is required but not provided or set in environment."
        super().__init__(message)


def _validate_api_key(groq_api_key: Optional[str] = None) -> str:
    """
    Validate and return the GROQ API key.

    Args:
        groq_api_key: Provided API key. If None, reads from environment.

    Returns:
        Validated API key string.

    Raises:
        MissingAPIKeyError: If no valid API key is found.
    """
    if groq_api_key is None:
        groq_api_key = os.getenv("GROQ_API_KEY")
    if not groq_api_key:
        raise MissingAPIKeyError()
    return groq_api_key


def transcribe_audio(audio_data: bytes) -> str:
    """
    Transcribe audio data to text.

    Args:
        audio_data: Audio data in bytes format

    Returns:
        Transcribed text or error message
    """
    temp_audio_path = None
    try:
        # Create a temporary file to store audio data
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_audio:
            temp_audio.write(audio_data)
            temp_audio_path = temp_audio.name

        # Load Whisper model and transcribe audio
        model = whisper.load_model("base.en")  # or any other model size
        result = model.transcribe(temp_audio_path)

        return result["text"]

    except Exception as e:
        return f"Transcription error: {str(e)}"

    finally:
        # Ensure a temporary file is deleted even if an error occurs
        if temp_audio_path and os.path.exists(temp_audio_path):
            os.unlink(temp_audio_path)


def generate_response(prompt: str, model_name: str, groq_api_key: Optional[str] = None) -> str:
    """
    Generate a response from a prompt using a language model.

    Args:
        prompt: Input text for the model
        model_name: Name of the model to use
        groq_api_key: API key for Groq. If None, uses GROQ_API_KEY from environment.

    Returns:
        Response generated by the model
    """
    try:
        # Validate and get API key
        groq_api_key = _validate_api_key(groq_api_key)

        # Initialize and invoke the model with API key
        model = init_chat_model(model_name, model_provider="groq", api_key=groq_api_key)
        response = model.invoke(prompt)

        return response.content if response else "No response generated."

    except Exception as e:
        return f"Error generating response: {e!s}"