import os
import io
import tempfile
from typing import Optional

import whisper
import torchaudio
from langchain.chat_models import init_chat_model


def transcribe_audio(audio_data: bytes) -> str:
    """
    Transcribe audio data to text.

    Args:
        audio_data: Audio data in bytes format

    Returns:
        Transcribed text or error message
    """
    temp_audio_path = None
    try:
        # Create a temporary file to store audio data
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_audio:
            temp_audio.write(audio_data)
            temp_audio_path = temp_audio.name

        # Load Whisper model and transcribe audio
        model = whisper.load_model("base.en")  # or any other model size
        result = model.transcribe(temp_audio_path)

        return result["text"]

    except Exception as e:
        return f"Transcription error: {str(e)}"

    finally:
        # Ensure a temporary file is deleted even if an error occurs
        if temp_audio_path and os.path.exists(temp_audio_path):
            os.unlink(temp_audio_path)


def generate_response(prompt: str, model_name: str, groq_api_key: str) -> str:
    """
    Generate a response from a prompt using a language model.

    Args:
        prompt: Input text for the model
        model_name: Name of the model to use
        groq_api_key: API key for Groq

    Returns:
        Response generated by the model
    """
    try:
        # Set API key
        os.environ["GROQ_API_KEY"] = groq_api_key

        # Initialize and invoke the model
        model = init_chat_model(model_name, model_provider="groq")
        response = model.invoke(prompt)

        return response.content if response else "No response generated."

    except Exception as e:
        return f"Error generating response: {str(e)}"